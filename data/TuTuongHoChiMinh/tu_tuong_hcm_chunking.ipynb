{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9598d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm đường dẫn: c:\\DACNTT2526\\IT_Project_2526\\src\n",
      "Thư mục hiện tại: c:\\DACNTT2526\\IT_Project_2526\\data\\TuTuongHoChiMinh\n"
     ]
    }
   ],
   "source": [
    "#Tạo đường dẫn chung để đọc utils\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#Tạo đường dẫn để gọi đến utils dễ hơn\n",
    "project_root = os.path.abspath(os.path.join(\"..\", '..', 'src'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(f\"Đã thêm đường dẫn: {project_root}\")\n",
    "print(f\"Thư mục hiện tại: {os.getcwd()}\")\n",
    "\n",
    "# Utils\n",
    "from utils import load_chunks_from_json\n",
    "from utils import save_chunks_to_json\n",
    "from utils import bm25_tokenize, text_to_sparse_vector_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15743167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTTextLine, LTChar\n",
    "from pypdf import PdfReader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import unicodedata\n",
    "import torch\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e1ee3",
   "metadata": {},
   "source": [
    "# ***Chunk văn bản***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_size_TrietHoc(pdf_path, total_pages):\n",
    "    '''\n",
    "        Hàm được sử dụng để kiểm tra xem toàn bộ các size text có trong tài liệu, chuẩn bị cho việc chunking\n",
    "        Các tham số:\n",
    "            - pdf_path: đường dẫn đến file pdf của môn Lịch sử đảng\n",
    "        \n",
    "        Hàm sẽ trả về 1 set chứa toàn bộ các text_size của tài liệu\n",
    "    '''\n",
    "    #Duyệt qua từng trang trong file pdf, bắt đầu từ trang 2 (bỏ qua trang bìa)\n",
    "    size_set = set()\n",
    "    for page_layout in extract_pages(pdf_path, page_numbers=range(2, total_pages)):\n",
    "        \n",
    "        #Duyệt qua từng phần tử trong trang\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "\n",
    "                # Duyet qua từng dòng chữ trong phần tử\n",
    "                for text_line in element:\n",
    "                    if isinstance(text_line, LTTextLine):\n",
    "                        \n",
    "                        #Lấy ra từng kí tự bên trong dòng chữ\n",
    "                        for obj in text_line:\n",
    "                            if isinstance(obj, LTChar):\n",
    "\n",
    "                                #Lấy ra thông tin của kí tự\n",
    "                                font = obj.fontname\n",
    "                                text = obj.get_text()\n",
    "                                text_size = obj.size\n",
    "\n",
    "                                size_set.add(text_size)\n",
    "    \n",
    "    return size_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121d1d2",
   "metadata": {},
   "source": [
    "# Xây dựng các hàm cần thiết cho quá trình xử lý văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c15a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    \"\"\"\n",
    "    Tách định danh và tiêu đề từ các dòng đề mục.\n",
    "\n",
    "    Ví dụ:\n",
    "    - 'Phần II  Những nguyên lý...' → ('Phần II', 'Những nguyên lý...')\n",
    "    - 'Chương V  Vật chất...'       → ('Chương V', 'Vật chất...')\n",
    "    - 'II- Nguồn gốc...'            → ('II-', 'Nguồn gốc...')\n",
    "    - '3. Kết cấu...'               → ('3.', 'Kết cấu...')\n",
    "    - 'b) Theo chiều sâu...'        → ('b)', 'Theo chiều sâu...')\n",
    "\n",
    "    Nếu không khớp, trả về ('None', original_line)\n",
    "    \"\"\"\n",
    "\n",
    "    line = line.strip()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\"\"^\n",
    "        (\n",
    "            (Phần|Chương)\\s+[IVXLCDM\\d]+            # Phần II, Chương V\n",
    "            |\n",
    "            [IVXLCDM]+[-\\.]                         # II- hoặc II.\n",
    "            |\n",
    "            \\d+[\\.\\)]                               # 3. hoặc 3)\n",
    "            |\n",
    "            [a-zA-Z][\\.\\)]                          # a) hoặc A.\n",
    "        )\n",
    "        \\s+(.+)                                     # phần còn lại là tiêu đề\n",
    "        \"\"\", re.VERBOSE | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        number = match.group(1).strip().rstrip(\".-)\")  # loại . - )\n",
    "        title = match.group(3).strip()\n",
    "        return number, title\n",
    "    else:\n",
    "        return \"\", line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa803958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Chuyển chuỗi thành lowercase, xóa dấu, và xóa toàn bộ khoảng trắng.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Bỏ dấu\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    # Xóa toàn bộ khoảng trắng (space, tab, newline)\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c048d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm dùng để nhận thông tin từ raw chunks, chuyển đổi sang DENSE vector để chuẩn bị nạp vào Database\n",
    "def TT_HCM_raw_to_dense(chapter, section, subsection, sub_subsection, content, model, max_chars = 2048, global_chunk_counter=None):\n",
    "\n",
    "    #Tách các đề mục sang số mục và tiêu đề\n",
    "    chapter_number, chapter_title = parse_line(chapter)\n",
    "    section_number, section_title = parse_line(section)\n",
    "    subsection_number, subsection_title = parse_line(subsection)\n",
    "    sub_subsection_number, sub_subsection_title = parse_line(sub_subsection)\n",
    "\n",
    "    chunk_type = 'EXERCISES' if (\"Câu hỏi ôn tập\" in section or \"câu hỏi ôn tập\" in section) else 'THEORY'\n",
    "\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chars,\n",
    "        chunk_overlap=300,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    content_chunks = splitter.split_text(content)\n",
    "\n",
    "    result = []\n",
    "    for i, content_piece in enumerate(content_chunks):\n",
    "        if global_chunk_counter is not None:\n",
    "            # Sử dụng global counter để đảm bảo hoàn toàn unique\n",
    "            unique_id = f\"TT_HCM_chunk_{global_chunk_counter['count']:05d}\"\n",
    "            global_chunk_counter['count'] += 1\n",
    "        else:\n",
    "            # Fallback về cách cũ nếu không có global counter\n",
    "            unique_id = f\"TT_HCM_{normalize_text(chapter_number) if chapter_number else 0}_{section_number if section_number else 0}_{subsection_number if section_number else 0}_{sub_subsection_number if sub_subsection_number else 0}_{i}\"  \n",
    "        chunk = {\n",
    "            \"id\": f\"{unique_id}\",\n",
    "            \"values\": model.encode(content).tolist(),\n",
    "            \"metadata\": {\n",
    "                \"subject\": \"Tư tưởng Hồ Chí Minh\",\n",
    "                \"chapter\": chapter_number,\n",
    "                \"chapter_title\": chapter_title,\n",
    "                \"section\": section_number,\n",
    "                \"section_title\": section_title,\n",
    "                \"subsection\": subsection_number,\n",
    "                \"subsection_title\": subsection_title,\n",
    "                \"sub_subsection\": sub_subsection_number,\n",
    "                \"sub_subsection_title\": sub_subsection_title,\n",
    "                \"content\": content_piece,\n",
    "                \"tokens\": len(content_piece),\n",
    "                \"type\": chunk_type\n",
    "            }\n",
    "        }\n",
    "        result.append(chunk)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb799225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "def text_to_sparse_vector_bm25(text, bm25, vocabulary):\n",
    "    tokens = bm25_tokenize(text)\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        idf = bm25.idf.get(word, 0)\n",
    "        tf = tokens.count(word)\n",
    "        vector[i] = idf * tf\n",
    "    indices = vector.nonzero()[0].tolist()\n",
    "    values = vector[indices].tolist()\n",
    "    return {\"indices\": indices, \"values\": values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ff6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm dùng để nhận thông tin từ raw chunks, chuyển đổi sang SPARSE vector để chuẩn bị nạp vào Database\n",
    "def TT_HCM_raw_to_sparse(chapter, section, subsection, sub_subsection, content, bm25 = None, vocabluary = None, max_chars = 2048, global_chunk_counter=None):\n",
    "\n",
    "    #Tách các đề mục sang số mục và tiêu đề\n",
    "    chapter_number, chapter_title = parse_line(chapter)\n",
    "    section_number, section_title = parse_line(section)\n",
    "    subsection_number, subsection_title = parse_line(subsection)\n",
    "    sub_subsection_number, sub_subsection_title = parse_line(sub_subsection)\n",
    "\n",
    "    chunk_type = 'EXERCISES' if (\"Câu hỏi ôn tập\" in section or \"câu hỏi ôn tập\" in section) else 'THEORY'\n",
    "\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_chars,\n",
    "        chunk_overlap=300,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    content_chunks = splitter.split_text(content)\n",
    "\n",
    "    result = []\n",
    "    for i, content_piece in enumerate(content_chunks):\n",
    "        if global_chunk_counter is not None:\n",
    "            # Sử dụng global counter để đảm bảo hoàn toàn unique\n",
    "            unique_id = f\"TT_HCM_chunk_{global_chunk_counter['count']:05d}\"\n",
    "            global_chunk_counter['count'] += 1\n",
    "        else:\n",
    "          # Fallback về cách cũ nếu không có global counter\n",
    "            unique_id = f\"TT_HCM_{normalize_text(chapter_number) if chapter_number else 0}_{section_number if section_number else 0}_{subsection_number if section_number else 0}_{sub_subsection_number if sub_subsection_number else 0}_{i}\"\n",
    "        chunk = {\n",
    "            \"id\": f\"{unique_id}\",\n",
    "            \"sparse_values\": text_to_sparse_vector_bm25(content_piece.strip(), bm25, vocabluary),\n",
    "            \"metadata\": {\n",
    "                \"subject\": \"Tư tưởng Hồ Chí Minh\",\n",
    "                \"chapter\": chapter_number,\n",
    "                \"chapter_title\": chapter_title,\n",
    "                \"section\": section_number,\n",
    "                \"section_title\": section_title,\n",
    "                \"subsection\": subsection_number,\n",
    "                \"subsection_title\": subsection_title,\n",
    "                \"sub_subsection\": sub_subsection_number,\n",
    "                \"sub_subsection_title\": sub_subsection_title,\n",
    "                \"content\": content_piece,\n",
    "                \"tokens\": len(content_piece),\n",
    "                \"type\": chunk_type\n",
    "            }\n",
    "        }\n",
    "        result.append(chunk)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f8980",
   "metadata": {},
   "source": [
    "# Xử lý tách văn bản thành các chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phân chia các tiêu đề\n",
    "# SUBSECTION_PATTERN = re.compile(r\"^\\s*\\d+[\\.\\)]\")    # 1. hoặc 2)\n",
    "# SUBSECTION_PATTERN_CHAP2 = re.compile(r\"^\\s*[IVX]+-\", re.IGNORECASE)   # 1. hoặc 2)\n",
    "# SUB_SUBSECTION_PATTERN = re.compile(r\"^\\s*[a-zA-Z][\\.\\)]\")  # a), b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc90056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm đung để kiểm tra xem tiêu đề hiện tại có phải sub section không\n",
    "# def is_subsection(line_chars, chapter_title):\n",
    "#     line = ''.join([obj.get_text() for obj in line_chars]).strip()\n",
    "#     if \"Chương II  \" in chapter_title:\n",
    "#         return bool(SUBSECTION_PATTERN_CHAP2.match(line))\n",
    "#     return bool(SUBSECTION_PATTERN.match(line))\n",
    "\n",
    "# #Hàm đung để kiểm tra xem tiêu đề hiện tại có phải subsub section không\n",
    "# def is_sub_subsection(line_chars, chapter_title):\n",
    "#     line = ''.join([obj.get_text() for obj in line_chars]).strip()\n",
    "#     if \"Chương II \" in chapter_title:\n",
    "#         return bool(SUBSECTION_PATTERN.match(line))\n",
    "#     return bool(SUB_SUBSECTION_PATTERN.match(line))\n",
    "\n",
    "# #Hàm đung để kiểm tra xem hiện tại có phải câu hỏi ôn tập hay không\n",
    "# def is_questions(line_chars):\n",
    "#     line = ''.join([obj.get_text() for obj in line_chars]).strip()\n",
    "#     return (\"Câu hỏi ôn tập\" in line or \"câu hỏi ôn tập\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf2b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trả về các raw chunks từ file PDF, đã được tối ưu cho tài liệu Tư tưởng Hồ Chí Minh\n",
    "def extract_raw_chunks_ttHCM(pdf_path, total_pages):\n",
    "    \"\"\"\n",
    "    Trích xuất các đoạn nội dung từ file PDF, đã được tối ưu để:\n",
    "    1. Gộp tiêu đề chương đa dòng.\n",
    "    2. Loại bỏ phần \"TÀI LIỆU THAM KHẢO\".\n",
    "    3. Loại bỏ các chú thích ở cuối trang.\n",
    "    4. Loại bỏ các chỉ mục footnote (ví dụ: ...word1.) trong nội dung.\n",
    "    \n",
    "    Trả về danh sách các dict: \n",
    "    {\"chapter\": ..., \"section\": ..., \"sub_section\": ..., \"sub_subsection\": ..., \"content\": ...}\n",
    "    \"\"\"\n",
    "\n",
    "    base_patterns = [\n",
    "        r'Downloaded by', r'Downloaded from', r'https?://', r'www\\.',\n",
    "        r'\\S+@\\S+\\.\\S+', r'^\\s*Page\\s*\\d+\\s*$', r'^[\\W_]{3,}$',\n",
    "        r'^[A-Za-z0-9]{6,}\\|\\d{3,}$', r'^\\s*Downloaded\\b', r'DOWNLOADED\\b',\n",
    "        r'lOMoARcPSD'\n",
    "    ]\n",
    "    compiled_patterns = [re.compile(p, re.I) for p in base_patterns]\n",
    "\n",
    "    def is_garbage_line(s):\n",
    "        if not s or not s.strip():\n",
    "            return True\n",
    "        s = s.replace('\\x0c','').strip()\n",
    "        if len(s) <= 2 and re.match(r'^[\\d\\W_]+$', s):\n",
    "            return True\n",
    "        for cp in compiled_patterns:\n",
    "            if cp.search(s):\n",
    "                return True\n",
    "        non_alnum = sum(1 for ch in s if not ch.isalnum() and not ch.isspace())\n",
    "        if len(s) > 0 and (non_alnum / len(s)) > 0.6:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    footnote_re = re.compile(r'^\\s*\\d+\\s+.*\\b(Nxb|NXB|Hà Nội|Hanoi|tr\\.|t\\.)\\b|,\\s*\\d{4}\\b', re.I)\n",
    "    chapter_pattern = re.compile(r\"^Chương ([IVXLCDM]+|\\d+)\\s*$\", re.IGNORECASE)\n",
    "    section_pattern = re.compile(r\"^[IVXLCDM]+\\.\\s*\")\n",
    "    sub_section_pattern = re.compile(r\"^\\d+\\.\\s*\")\n",
    "    sub_sub_section_pattern = re.compile(r\"^[a-z]\\.\\s*\")\n",
    "\n",
    "    raw_chunks = []\n",
    "    is_content = False\n",
    "    in_references_section = False  # Flag trạng thái cho mục TÀI LIỆU THAM KHẢO\n",
    "\n",
    "    curr_chapter_line = \"\"\n",
    "    curr_section_line = \"\"\n",
    "    curr_sub_section_line = \"\"\n",
    "    curr_sub_sub_section_line = \"\"\n",
    "    curr_content_line = \"\"\n",
    "\n",
    "    page_range = range(5, total_pages)\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path, page_numbers=page_range):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                for text_line in element:\n",
    "                    if not isinstance(text_line, LTTextLine):\n",
    "                        continue\n",
    "                        \n",
    "                    line_text = text_line.get_text().replace('\\x0c','').strip()\n",
    "                    if is_garbage_line(line_text) or line_text.isdigit():\n",
    "                        continue\n",
    "\n",
    "                    first_char = next(iter(text_line), None)\n",
    "                    font_name = \"\"\n",
    "                    font_size = first_char.size\n",
    "                    if isinstance(first_char, LTChar):\n",
    "                        font_name = first_char.fontname\n",
    "\n",
    "                    is_bold = \"Bold\" in font_name\n",
    "                    is_italic = \"Italic\" in font_name\n",
    "\n",
    "                    # Loại bỏ chú thích cuối trang dựa trên font size \n",
    "                    is_small_font = font_size < 12\n",
    "                    if is_small_font or footnote_re.search(line_text):\n",
    "                        continue\n",
    "\n",
    "                    # Xử lý trạng thái \"TÀI LIỆU THAM KHẢO\" \n",
    "                    is_new_header = any([p.match(line_text) for p in [chapter_pattern, section_pattern]])\n",
    "                    if in_references_section:\n",
    "                        if is_new_header:\n",
    "                            in_references_section = False # Thoát khỏi chế độ bỏ qua\n",
    "                        else:\n",
    "                            continue # Bỏ qua các dòng trong mục tham khảo\n",
    "\n",
    "                    if line_text.strip().upper() == 'TÀI LIỆU THAM KHẢO':\n",
    "                        save_current_chunk()\n",
    "                        in_references_section = True\n",
    "                        continue\n",
    "\n",
    "                    def save_current_chunk():\n",
    "                        nonlocal is_content, curr_content_line\n",
    "                        if is_content and curr_content_line.strip():\n",
    "                            raw_chunks.append({\n",
    "                                \"chapter\": curr_chapter_line.strip(),\n",
    "                                \"section\": curr_section_line.strip(),\n",
    "                                \"sub_section\": curr_sub_section_line.strip(),\n",
    "                                \"sub_subsection\": curr_sub_sub_section_line.strip(),\n",
    "                                \"content\": curr_content_line.strip()\n",
    "                            })\n",
    "                        is_content = False\n",
    "                        curr_content_line = \"\"\n",
    "\n",
    "                    # 1. Kiểm tra Chương\n",
    "                    if chapter_pattern.match(line_text) and is_bold:\n",
    "                        save_current_chunk()\n",
    "                        curr_chapter_line = line_text\n",
    "                        curr_section_line = \"\"\n",
    "                        curr_sub_section_line = \"\"\n",
    "                        curr_sub_sub_section_line = \"\"\n",
    "                    \n",
    "                    # 2. Kiểm tra Mục (I, II, ...)\n",
    "                    elif section_pattern.match(line_text) and is_bold:\n",
    "                        save_current_chunk()\n",
    "                        curr_section_line = line_text\n",
    "                        curr_sub_section_line = \"\"\n",
    "                        curr_sub_sub_section_line = \"\"\n",
    "\n",
    "                    # 3. Kiểm tra Mục con (1, 2, ...)\n",
    "                    elif sub_section_pattern.match(line_text) and is_bold:\n",
    "                        save_current_chunk()\n",
    "                        curr_sub_section_line = line_text\n",
    "                        curr_sub_sub_section_line = \"\"\n",
    "\n",
    "                    # 4. Kiểm tra Mục con cấp 2 (a, b, ...)\n",
    "                    elif sub_sub_section_pattern.match(line_text) and is_bold and is_italic:\n",
    "                        save_current_chunk()\n",
    "                        curr_sub_sub_section_line = line_text\n",
    "                        \n",
    "                    # 5. Xử lý nội dung hoặc phần còn lại của tiêu đề chương\n",
    "                    else:\n",
    "                        # Nếu đã có chương, chưa có mục, và dòng hiện tại là IN HOA + in đậm\n",
    "                        # -> coi nó là một phần của tiêu đề chương.\n",
    "                        # Thêm điều kiện len(line_text.split()) > 2 để chỉ gộp những cụm từ dài\n",
    "                        # Tương tự với mục và mục con.\n",
    "                        if (curr_chapter_line and not curr_section_line and\n",
    "                                is_bold and line_text.isupper() and len(line_text.split()) > 2):\n",
    "                            curr_chapter_line += \" \" + line_text\n",
    "                        elif (curr_section_line and not curr_sub_section_line and\n",
    "                                is_bold):\n",
    "                            curr_section_line += \" \" + line_text\n",
    "                        elif (curr_sub_section_line and not curr_sub_sub_section_line and\n",
    "                                is_bold):\n",
    "                            curr_sub_section_line += \" \" + line_text\n",
    "                        elif (curr_sub_sub_section_line and\n",
    "                                is_bold and is_italic):\n",
    "                            curr_sub_sub_section_line += \" \" + line_text\n",
    "                        else:\n",
    "                            # Ngược lại, coi là nội dung bình thường\n",
    "                            if footnote_re.search(line_text):\n",
    "                                continue\n",
    "                            # Regex để loại bỏ các số footnote, ví dụ: \"word”1.\" -> \"word”.\"\n",
    "                            # Quy tắc: tìm một ký tự (chữ hoặc dấu ngoặc kép), theo sau là một chữ số (1-9), \n",
    "                            # và kết thúc bằng một ký tự khoảng trắng hoặc dấu câu.\n",
    "                            # Thay thế bằng ký tự đầu và cuối, bỏ qua chữ số ở giữa.\n",
    "                            line_text = re.sub(r'([a-zA-Zà-ỹÀ-Ỹ”\\'\"])([1-9])([\\s\\.,\\);]|$)', r'\\1\\3', line_text)\n",
    "                            is_content = True\n",
    "                            curr_content_line += line_text + \" \"\n",
    "\n",
    "    if curr_content_line.strip():\n",
    "        raw_chunks.append({\n",
    "            \"chapter\": curr_chapter_line.strip(),\n",
    "            \"section\": curr_section_line.strip(),\n",
    "            \"sub_section\": curr_sub_section_line.strip(),\n",
    "            \"sub_subsection\": curr_sub_sub_section_line.strip(),\n",
    "            \"content\": curr_content_line.strip()\n",
    "        })\n",
    "\n",
    "    return raw_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc7fba",
   "metadata": {},
   "source": [
    "# ***Tạo ra Dense Vector và Sparse Vector từ Raw***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dad24a",
   "metadata": {},
   "source": [
    "## Tạo Dense Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "965b4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_with_embedding(raw_chunks, embedding_model):\n",
    "    \"\"\"\n",
    "    Nhận vào danh sách raw_chunks, sau đó gọi hàm split_chunk_langchain để xử lý nhỏ ra và thêm embedding nếu cần.\n",
    "    \"\"\"\n",
    "    final_chunks = []\n",
    "    global_chunk_counter = {'count': 0}  # Khởi tạo global counter\n",
    "    for chunk in raw_chunks:\n",
    "        split_chunks = TT_HCM_raw_to_dense(\n",
    "            chunk['chapter'],\n",
    "            chunk['section'],\n",
    "            chunk['sub_section'],\n",
    "            chunk['sub_subsection'],\n",
    "            chunk['content'],\n",
    "            max_chars=2048,\n",
    "            model=embedding_model,\n",
    "            global_chunk_counter=global_chunk_counter\n",
    "        )\n",
    "        final_chunks.extend(split_chunks)\n",
    "\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097e03d",
   "metadata": {},
   "source": [
    "## Tạo Sparse Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cc912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_with_sparse(raw_chunks, bm25, vocabulary):\n",
    "    \"\"\"\n",
    "    Nhận vào danh sách raw_chunks, sau đó gọi hàm split_chunk_langchain để xử lý nhỏ ra và thêm embedding nếu cần.\n",
    "    \"\"\"\n",
    "    final_chunks = []\n",
    "    global_chunk_counter = {'count': 0}  # Khởi tạo global counter\n",
    "    for chunk in raw_chunks:\n",
    "        split_chunks = TT_HCM_raw_to_sparse(\n",
    "            chunk['chapter'],\n",
    "            chunk['section'],\n",
    "            chunk['sub_section'],\n",
    "            chunk['sub_subsection'],\n",
    "            chunk['content'],\n",
    "            bm25=bm25,\n",
    "            vocabluary=vocabulary,\n",
    "            global_chunk_counter=global_chunk_counter\n",
    "        )\n",
    "        final_chunks.extend(split_chunks)\n",
    "\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441439e",
   "metadata": {},
   "source": [
    "# ***Tạo các file json cần thiết***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9aa6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_chunks_to_json(chunks, output_path):\n",
    "    \"\"\"\n",
    "    Lưu danh sách các chunk (list of dict) ra file JSON.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # Tạo folder nếu chưa có\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Đã lưu {len(chunks)} chunks vào: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6092a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc data từ file json\n",
    "def load_chunks_from_json(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ba5fb",
   "metadata": {},
   "source": [
    "# ***Main***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537b33f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số trang trong PDF: 150\n",
      "✅ Đã lưu 211 chunks vào: ./chunks/TT_HCM_Dense.json\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"./Tu_tuong_Ho_Chi_Minh.pdf\"\n",
    "# API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# HOST_DENSE = os.getenv(\"HOST_DENSE\")\n",
    "# HOST_SPARSE = os.getenv(\"HOST_SPARSE\")\n",
    "\n",
    "# Lấy số trang trong file PDF\n",
    "reader = PdfReader(pdf_path)\n",
    "total_pages = len(reader.pages)\n",
    "print(\"Số trang trong PDF:\", total_pages)\n",
    "\n",
    "# Lấy ra toàn bộ fontsize của file PDF\n",
    "# size_set = get_text_size_TrietHoc(pdf_path, total_pages)\n",
    "# print(f'size set: {size_set}')\n",
    "\n",
    "# - Phân loại các nội dung (Format của môn Triết học sẽ theo thứ tự: Phần -> Chương -> I, II, III,... -> 1, 2,... -> a, b, c,....):\n",
    "#     - Kích thước chữ >= 22: Các phần và tiêu đề của các phần đó\n",
    "#     - Kích thước chữ == 18: Chương và các tiêu đề của Chương\n",
    "#     - Kích thước chữ == 14 (> 13.5 and < 14): Các mục I, II, III (Có thể là ABC đối với chương II và 123 đói với chương IV)\n",
    "#     - Kích thước chữ == 13 (13 <= text_size < 13.1): Các mục con như 1, 2, 3,... (Đối với chương 2 sẽ là I, II, III,...) và các mục nhỏ hơn như a, b, c....\n",
    "#     - Kích thước chữ == 12 (11.6 <= text_size < 12,4): Nội dung của môn\n",
    "\n",
    "# Đọc file PDF, chuyển qua RAW chunks\n",
    "# TT_HCM_raw_chunks = extract_raw_chunks_ttHCM(pdf_path, total_pages)\n",
    "# save_chunks_to_json(TT_HCM_raw_chunks, r\"./chunks/Tu_tuong_HCM_raw.json\")\n",
    "\n",
    "TT_HCM_raw_chunks = load_chunks_from_json(r\"./chunks/Tu_tuong_HCM_raw.json\")\n",
    "# Đưa RAW chunks vào chuyển đổi sang Dense Vector\n",
    "embedding_model = SentenceTransformer(\"AITeamVN/Vietnamese_Embedding\")\n",
    "embedding_model.max_seq_length = 2048\n",
    "TT_HCM_dense_vector = chunk_with_embedding(TT_HCM_raw_chunks, embedding_model)\n",
    "\n",
    "# Đưa RAW chunks vào chuyển đổi sang Sparse Vector\n",
    "# corpus_texts = [chunk[\"content\"] for chunk in TT_HCM_raw_chunks]\n",
    "# tokenized_corpus = [bm25_tokenize(text) for text in corpus_texts]\n",
    "# bm25 = BM25Okapi(tokenized_corpus)\n",
    "# vocabulary = list(bm25.idf.keys())\n",
    "# TT_HCM_sparse_vector = chunk_with_sparse(TT_HCM_raw_chunks, bm25, vocabulary)\n",
    "\n",
    "\n",
    "#Lưu các Vector vừa tạo được vào file Json\n",
    "\n",
    "#Lưu Dense Vector\n",
    "save_chunks_to_json(TT_HCM_dense_vector, r\"./chunks/TT_HCM_Dense.json\")\n",
    "\n",
    "#Lưu Sparse Vector\n",
    "# save_chunks_to_json(TrietHoc_sparse_vector, r\"./TrietHoc_Sparse.json\")                    \n",
    "\n",
    "# Đọc file Json \n",
    "# tu_tuong_HCM_dense_vector = load_chunks_from_json(r\"./TT_HCM_Dense.json\")\n",
    "# tu_tuong_HCM_sparse_vector = load_chunks_from_json(r\"./TT_HCM_Sparse.json\")\n",
    "\n",
    "\n",
    "# Upsert Vector lên các Database\n",
    "# from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "# pc = Pinecone(api_key=API_KEY)\n",
    "\n",
    "# dense_index = pc.Index(host=HOST_DENSE)\n",
    "# dense_index.upsert(\n",
    "#   vectors = tu_tuong_HCM_dense_vector,\n",
    "#   namespace=\"tu-tuong-HCM\"\n",
    "# )\n",
    "\n",
    "# sparse_index = pc.Index(host=HOST_SPARSE)\n",
    "# sparse_index.upsert(\n",
    "#   vectors = tu_tuong_HCM_sparse_vector,\n",
    "#   namespace=\"tu-tuong-HCM\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeee1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1.0\n",
      "  lOMoARcPSD|38213158\n",
      "----------------------------------------\n",
      "Size: 5.799999999999997\n",
      "  1 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ XI, Nxb Chính trị quốc gia, Hà\n",
      "  3 Đảng Cộng sản Việt Nam: Văn kiện Đảng Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2004, t.37, tr.474.\n",
      "  4Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ V, Nxb Sự thật, Hà Nội, t. 3, tr.61.\n",
      "  4 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ IX, Nxb Chính trị quốc gia, Hà\n",
      "  3  Xem  GS,TS  Mạch  Quang   Thắng,  PGS,TS  Bùi  Đình  Phong,  TS   Chu Đức  Tính  (Đồng  Chủ  biên):\n",
      "----------------------------------------\n",
      "Size: 5.800000000000011\n",
      "  1 Đảng Cộng sản Việt Nam: Văn kiện Đảng Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2001, t.12, tr. 9.\n",
      "  2 Đảng Cộng sản Việt Nam: Văn kiện Đảng Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2004, t.30, tr.275.\n",
      "  1Đảng Cộng sản Việt Nam: Văn kiện Đảng Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2006,  t.47, tr.807.\n",
      "  2 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ VII, Nxb Sự thật, Hà Nội, 1991,\n",
      "  3 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ VII, Nxb Sự thật, Hà Nội, 1991,\n",
      "----------------------------------------\n",
      "Size: 7.0\n",
      "  1 Sau những nội dung nhập môn (Chương I) và sau khi nêu lên cơ sở hình thành, phát triển tư tưởng Hồ\n",
      "  4  Ph.Ăngghen: “Chống Đuyrinh”, trong C.Mác và Ph.Ăngghen: Toàn tập, Nxb Chính trị quốc gia Sự\n",
      "  3 Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.5, tr.622.\n",
      "  2 Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.4, tr.170.\n",
      "  6 Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.13, tr.69.\n",
      "----------------------------------------\n",
      "Size: 7.000000000000014\n",
      "  22 Hồ Chí Minh: Toàn tập,  Nxb Chính trị quốc gia, Hà Nội, 2011, t.3, tr. 230.\n",
      "  3 Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.6, tr.127.\n",
      "----------------------------------------\n",
      "Size: 7.499999999999943\n",
      "  đứng lên đánh thực dân Pháp để cứu Tổ quốc”1.\n",
      "  hướng dẫn, giúp đỡ kinh tế hợp tác xã5.\n",
      "  công việc của dân, là trách nhiệm của dân4. Với tư cách là những động lực thúc đẩy\n",
      "  người của chủ nghĩa xã hội, có tư tưởng và tác phong xã hội chủ nghĩa 5. Trong bài\n",
      "----------------------------------------\n",
      "Size: 7.5\n",
      "  soi đường cho sự nghiệp cách mạng của nhân dân ta giành thắng lợi”1.\n",
      "  mạng phù hợp...1\n",
      "  hoàn toàn\"1.\n",
      "  dân tộc ta, nhân dân ta và non sông đất nước ta”2. Tiếp nối sự đánh giá ấy, Đại hội\n",
      "  nhân quốc tế”3. Tiếp theo, tháng 3-1982, Đại hội đại biểu toàn quốc lần thứ V của\n",
      "----------------------------------------\n",
      "Size: 7.500000000000028\n",
      "  mắt sáng, một mắt mờ”3,“vì kém lý luận, cho nên gặp mọi việc không biết xem xét\n",
      "  mới”6.Muốn làm được như vậy, phải chú ý phát hiện, xây dựng những điển hình\n",
      "----------------------------------------\n",
      "Size: 7.500000000000057\n",
      "  nghĩa chân chính nhất, chắc chắn nhất, cách mệnh nhất là chủ nghĩa Lênin”2.\n",
      "----------------------------------------\n",
      "Size: 8.0\n",
      "  Downloaded by Qu?c Th?nh (dhdncndhxn650@gmail.com)\n",
      "----------------------------------------\n",
      "Size: 9.999999999999972\n",
      "  2 Hồ Chí Minh: Toàn tập, Nxb. Chính trị quốc gia, Hà Nội, 2011, t.6, tr.123.\n",
      "----------------------------------------\n",
      "Size: 9.999999999999986\n",
      "  2 Đảng Cộng sản Việt Nam: Văn kiện Đảng Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2004, t.30, tr.275.\n",
      "  2 Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.5, tr.274.\n",
      "  Nội, 2015, tr.48.\n",
      "  3Hồ Chí Minh: Toàn tập, NxbChính trị quốc gia, Hà Nội, 2011, t.4, tr.522.\n",
      "  4Hồ Chí Minh: Toàn tập, Nxb Chính trị quốc gia, Hà Nội, 2011, t.4, tr.64.\n",
      "----------------------------------------\n",
      "Size: 10.0\n",
      "  1 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ XI, Nxb Chính trị quốc gia, Hà\n",
      "  Nội, 2011, tr.88.\n",
      "  1 Sau những nội dung nhập môn (Chương I) và sau khi nêu lên cơ sở hình thành, phát triển tư tưởng Hồ\n",
      "  Chí Minh (Chương II), giáo trình này chỉ đề cập một số nội dung cơ bản của tư tưởng Hồ Chí Minh trong\n",
      "  khuôn khổ thời lượng đào tạo bậc đại học (từ Chương III đến Chương VI).\n",
      "----------------------------------------\n",
      "Size: 10.000000000000014\n",
      "  3 Đảng Cộng sản Việt Nam: Văn kiện Đại hội đại biểu toàn quốc lần thứ VII, Nxb Sự thật, Hà Nội, 1991,\n",
      "  Nội, 2016, tr.199.\n",
      "  1997, tr.24-25.\n",
      "  11 Ban nghiên cứu lịch sử Đảng Trung ương: Chủ tịch Hồ Chí Minh - Tiểu sử sự nghiệp, Nxb Sự thật, Hà\n",
      "  3 C.Mác và Ph.Ăngghen: Toàn tập, Nxb Chính trị quốc gia Sự thật, Hà Nội, 2002, t.23, tr.1043.\n",
      "----------------------------------------\n",
      "Size: 11.999999999999993\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "----------------------------------------\n",
      "Size: 12.999999999999943\n",
      "  cách mạng Việt Nam, từ đó có tư tưởng, tình cảm tích cực trong việc học tập và làm\n",
      "  lên một khát khao to lớn của dân tộc ta là, luôn mong nuốn có được một nền độc lập\n",
      "----------------------------------------\n",
      "Size: 12.999999999999972\n",
      "  8. Hồ Chí Minh: Toàn tập, t.15, Nxb Chính trị quốc gia, Hà Nội, 2011.\n",
      "  của Đảng”, Toàn tập, t.7, Nxb Chính trị quốc gia, Hà Nội, 2011.\n",
      "  Chủ nghĩa xã hội là cơ sở, là tiền đề để tiến tới chế độ xã hội hòa bình, đoàn\n",
      "  quần chúng bị áp bức và bóc lột; là khoa học về sự thắng lợi của chủ nghĩa xã hội ở\n",
      "  LIỀN VỚI CHỦ NGHĨA XÃ HỘI TRONG SỰ NGHIỆP CÁCH MẠNG VIỆT\n",
      "----------------------------------------\n",
      "Size: 12.999999999999986\n",
      "  trong cách mạng xã hội chủ nghĩa. Như vậy, sự lãnh đạo của Đảng Cộng sản Việt\n",
      "----------------------------------------\n",
      "Size: 13.0\n",
      "  MỤC TIÊU\n",
      "  - Về kiến thức\n",
      "  Góp phần trang bị cho sinh viên những kiến thức cơ bản về một số vấn đề\n",
      "  chung (nhập môn) của môn học Tư tưởng Hồ Chí Minh.\n",
      "  - Về kỹ năng\n",
      "----------------------------------------\n",
      "Size: 13.000000000000014\n",
      "  nêu: Dĩ bất biến ứng vạn biến.\n",
      "  mới hiện nay và trong tương lai.\n",
      "  trào cộng sản quốc tế,  phong trào vì hòa bình, hợp tác và phát triển.\n",
      "  dân tộc; nắm được tính quy luật của cách mạng Việt Nam: độc lập dân tộc gắn liền\n",
      "  Cương lĩnh xây dựng đất nước trong thời kỳ quá độ lên chủ nghĩa xã hội. Đến Đại\n",
      "----------------------------------------\n",
      "Size: 13.000000000000028\n",
      "  hội cũng thuộc về nhân dân3.\n",
      "  Khi khẳng định “dân làm chủ” và “dân là chủ”, Hồ Chí Minh đã khẳng định\n",
      "  nghĩa vụ công dân theo tinh thần của Hiến pháp hiện hành.\n",
      "  người như một thì nước ta độc lập, tự do. Trái lại lúc nào dân ta không đoàn kết thì\n",
      "  trong mỗi cá nhân cũng như mỗi cộng đồng đều có những ưu điểm, khuyết điểm,\n",
      "----------------------------------------\n",
      "Size: 13.000000000000057\n",
      "  dân Việt Nam yêu nước, xây dựng con người Việt Nam có năng lực và phẩm chất\n",
      "  kiện tiên quyết làm cho Đảng mạnh và làm cho cách mạng đi mau đến thắng lợi\n",
      "  Hồ Chí Minh đã trở thành một tài sản tinh thần quý báu của Đảng ta và của cả dân\n",
      "  Minh đối với quá trình phát triển của dân tộc Việt Nam cũng như đối với quá trình\n",
      "  đại. Quá trình này chính là sự thể hiện chủ nghĩa Mác - Lênin luôn luôn được bổ\n",
      "----------------------------------------\n",
      "Size: 14.0\n",
      "  Chương I\n",
      "  KHÁI NIỆM, ĐỐI TƯỢNG, PHƯƠNG PHÁP NGHIÊN CỨU\n",
      "  VÀ Ý NGHĨA HỌC TẬP MÔN TƯ TƯỞNG HỒ CHÍ MINH\n",
      "  Chương II\n",
      "  CƠ SỞ, QUÁ TRÌNH HÌNH THÀNH VÀ PHÁT TRIỂN\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hàm dùng để lấy mẫu các text có kích thước khác nhau trong file PDF\n",
    "# from collections import defaultdict\n",
    "\n",
    "# def sample_unique_texts_by_size(pdf_path, total_pages, max_samples=5):\n",
    "#     samples = defaultdict(list) \n",
    "#     seen = defaultdict(set) # Để theo dõi các dòng đã thấy cho mỗi kích thước\n",
    "#     for page_layout in extract_pages(pdf_path, page_numbers=range(5, total_pages)):\n",
    "#         for element in page_layout:\n",
    "#             if isinstance(element, LTTextContainer):\n",
    "#                 for text_line in element:\n",
    "#                     if isinstance(text_line, LTTextLine):\n",
    "#                         line_text = text_line.get_text().strip()\n",
    "#                         for obj in text_line:\n",
    "#                             if isinstance(obj, LTChar):\n",
    "#                                 text_size = obj.size\n",
    "#                                 # Chỉ lấy mẫu nếu chưa đủ số mẫu và chưa thấy dòng này với kích thước này\n",
    "#                                 if (line_text not in seen[text_size] and \n",
    "#                                     len(samples[text_size]) < max_samples and \n",
    "#                                     line_text):\n",
    "#                                     samples[text_size].append(line_text)\n",
    "#                                     seen[text_size].add(line_text)\n",
    "#     # In ra các mẫu đã lấy\n",
    "#     for size in sorted(samples):\n",
    "#         print(f\"Size: {size}\")\n",
    "#         for example in samples[size]:\n",
    "#             print(f\"  {example}\")\n",
    "#         print(\"-\" * 40)\n",
    "\n",
    "# sample_unique_texts_by_size(pdf_path, total_pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
